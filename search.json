[{"path":"https://docs.ropensci.org/googleLanguageR/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to googleLanguageR","title":"Contributing to googleLanguageR","text":"Thank interest contributing project! run unit tests, saved API calls cached tests/testthat/mock folder. substitute API call Google avoid authentication. API calls Cloud Speech API translation varies slightly, test success judged string within 10 characters test string. test , stringdist package needed (package Suggests) run integration tests hit API, need add authentication service JSON file Google Cloud projects. Save file computer set environment variable GL_AUTH pointing file location. present, (CRAN Travis) integration tests skipped. need enable following APIs: Google Cloud Speech API Google Cloud Natural Language API Google Cloud Translation API create new mock files, needs fully load package :","code":"remotes::install_github(\"ropensci/googleLanguageR\") setwd(\"tests/testthat\") source(\"test_unit.R\")"},{"path":"https://docs.ropensci.org/googleLanguageR/CONTRIBUTING.html","id":"contributor-covenant-code-of-conduct","dir":"","previous_headings":"","what":"Contributor Covenant Code of Conduct.","title":"Contributing to googleLanguageR","text":"contributors joy creating sharing advancing knowledge. Treat respect deserves. main language English. community tolerate everything intolerance. assumed everyone trying tolerant repeatedly prove otherwise. Don’t break laws copyrights contributions, credit sources due.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/articles/nlp.html","id":"demo-for-entity-analysis","dir":"Articles","previous_headings":"","what":"Demo for Entity Analysis","title":"Google Natural Language API","text":"can pass vector text call API element. return list responses, response list tibbles holding different types analysis. text entry returned tibbles Sentence structure sentiment: Information words (tokens) within text: entities within text identified, optional wikipedia URL available. Sentiment entire text: category text defined list . language text: original passed text, aid working output:","code":"library(googleLanguageR)  # random text form wikipedia texts <- c(\"Norma is a small constellation in the Southern Celestial Hemisphere between Ara and Lupus, one of twelve drawn up in the 18th century by French astronomer Nicolas Louis de Lacaille and one of several depicting scientific instruments. Its name refers to a right angle in Latin, and is variously considered to represent a rule, a carpenter's square, a set square or a level. It remains one of the 88 modern constellations. Four of Norma's brighter stars make up a square in the field of faint stars. Gamma2 Normae is the brightest star with an apparent magnitude of 4.0. Mu Normae is one of the most luminous stars known, but is partially obscured by distance and cosmic dust. Four star systems are known to harbour planets. \",           \"Solomon Wariso (born 11 November 1966 in Portsmouth) is a retired English sprinter who competed primarily in the 200 and 400 metres.[1] He represented his country at two outdoor and three indoor World Championships and is the British record holder in the indoor 4 × 400 metres relay.\") nlp_result <- gl_nlp(texts) str(nlp_result, max.level = 2) List of 7  $ sentences        :List of 2   ..$ :'data.frame':    7 obs. of  4 variables:   ..$ :'data.frame':    1 obs. of  4 variables:  $ tokens           :List of 2   ..$ :'data.frame':    139 obs. of  17 variables:   ..$ :'data.frame':    54 obs. of  17 variables:  $ entities         :List of 2   ..$ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':    52 obs. of  9 variables:   ..$ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':    8 obs. of  9 variables:  $ language         : chr [1:2] \"en\" \"en\"  $ text             : chr [1:2] \"Norma is a small constellation in the Southern Celestial Hemisphere between Ara and Lupus, one of twelve drawn \"| __truncated__ \"Solomon Wariso (born 11 November 1966 in Portsmouth) is a retired English sprinter who competed primarily in th\"| __truncated__  $ documentSentiment:Classes ‘tbl_df’, ‘tbl’ and 'data.frame':  2 obs. of  2 variables:   ..$ magnitude: num [1:2] 2.4 0.1   ..$ score    : num [1:2] 0.3 0.1  $ classifyText     :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':  1 obs. of  2 variables:   ..$ name      : chr \"/Science/Astronomy\"   ..$ confidence: num 0.93 ## sentences structure nlp_result$sentences[[2]]  content 1 Solomon Wariso (born 11 November 1966 in Portsmouth) is a retired English sprinter who competed primarily in the 200 and 400 metres.[1] He represented his country at two outdoor and three indoor World Championships and is the British record holder in the indoor 4 × 400 metres relay.   beginOffset magnitude score 1           0       0.1   0.1 # word tokens data str(nlp_result$tokens[[1]]) 'data.frame':   139 obs. of  17 variables:  $ content       : chr  \"Norma\" \"is\" \"a\" \"small\" ...  $ beginOffset   : int  0 6 9 11 17 31 34 38 47 57 ...  $ tag           : chr  \"NOUN\" \"VERB\" \"DET\" \"ADJ\" ...  $ aspect        : chr  \"ASPECT_UNKNOWN\" \"ASPECT_UNKNOWN\" \"ASPECT_UNKNOWN\" \"ASPECT_UNKNOWN\" ...  $ case          : chr  \"CASE_UNKNOWN\" \"CASE_UNKNOWN\" \"CASE_UNKNOWN\" \"CASE_UNKNOWN\" ...  $ form          : chr  \"FORM_UNKNOWN\" \"FORM_UNKNOWN\" \"FORM_UNKNOWN\" \"FORM_UNKNOWN\" ...  $ gender        : chr  \"GENDER_UNKNOWN\" \"GENDER_UNKNOWN\" \"GENDER_UNKNOWN\" \"GENDER_UNKNOWN\" ...  $ mood          : chr  \"MOOD_UNKNOWN\" \"INDICATIVE\" \"MOOD_UNKNOWN\" \"MOOD_UNKNOWN\" ...  $ number        : chr  \"SINGULAR\" \"SINGULAR\" \"NUMBER_UNKNOWN\" \"NUMBER_UNKNOWN\" ...  $ person        : chr  \"PERSON_UNKNOWN\" \"THIRD\" \"PERSON_UNKNOWN\" \"PERSON_UNKNOWN\" ...  $ proper        : chr  \"PROPER\" \"PROPER_UNKNOWN\" \"PROPER_UNKNOWN\" \"PROPER_UNKNOWN\" ...  $ reciprocity   : chr  \"RECIPROCITY_UNKNOWN\" \"RECIPROCITY_UNKNOWN\" \"RECIPROCITY_UNKNOWN\" \"RECIPROCITY_UNKNOWN\" ...  $ tense         : chr  \"TENSE_UNKNOWN\" \"PRESENT\" \"TENSE_UNKNOWN\" \"TENSE_UNKNOWN\" ...  $ voice         : chr  \"VOICE_UNKNOWN\" \"VOICE_UNKNOWN\" \"VOICE_UNKNOWN\" \"VOICE_UNKNOWN\" ...  $ headTokenIndex: int  1 1 4 4 1 4 9 9 9 5 ...  $ label         : chr  \"NSUBJ\" \"ROOT\" \"DET\" \"AMOD\" ...  $ value         : chr  \"Norma\" \"be\" \"a\" \"small\" ... nlp_result$entities [[1]] # A tibble: 52 x 9    name           type         salience mid   wikipedia_url magnitude score beginOffset mention_type    <chr>          <chr>           <dbl> <chr> <chr>             <dbl> <dbl>       <int> <chr>         1 angle          OTHER         0.0133  NA    NA                  0     0           261 COMMON        2 Ara            ORGANIZATION  0.0631  NA    NA                  0     0            76 PROPER        3 astronomer     NA           NA       NA    NA                 NA    NA           144 COMMON        4 carpenter      PERSON        0.0135  NA    NA                  0     0           328 COMMON        5 constellation  OTHER         0.150   NA    NA                  0     0            17 COMMON        6 constellations OTHER         0.0140  NA    NA                  0.9   0.9         405 COMMON        7 distance       OTHER         0.00645 NA    NA                  0     0           649 COMMON        8 dust           OTHER         0.00645 NA    NA                  0.3  -0.3         669 COMMON        9 field          LOCATION      0.00407 NA    NA                  0.6  -0.6         476 COMMON       10 French         LOCATION      0.0242  NA    NA                  0     0           137 PROPER       # ... with 42 more rows  [[2]] # A tibble: 8 x 9   name                type         salience mid         wikipedia_url    magnitude score beginOffset mention_type   <chr>               <chr>           <dbl> <chr>       <chr>                <dbl> <dbl>       <int> <chr>        1 British             LOCATION       0.0255 NA          NA                     0     0           226 PROPER       2 country             LOCATION       0.0475 NA          NA                     0     0           155 COMMON       3 English             OTHER          0.0530 NA          NA                     0     0            66 PROPER       4 Portsmouth          LOCATION       0.0530 /m/0619_    https://en.wiki…       0     0            41 PROPER       5 record holder       PERSON         0.0541 NA          NA                     0     0           234 COMMON       6 Solomon Wariso      ORGANIZATION   0.156  /g/120x5nf6 https://en.wiki…       0     0             0 PROPER       7 sprinter            PERSON         0.600  NA          NA                     0     0            74 COMMON       8 World Championships EVENT          0.0113 NA          NA                     0.1   0.1         195 PROPER nlp_result$documentSentiment # A tibble: 2 x 2   magnitude score       <dbl> <dbl> 1       2.4   0.3 2       0.1   0.1 nlp_result$classifyText # A tibble: 1 x 2   name               confidence   <chr>                   <dbl> 1 /Science/Astronomy       0.93 nlp_result$language # [1] \"en\" \"en\" nlp_result$text [1] \"Norma is a small constellation in the Southern Celestial Hemisphere between Ara and Lupus, one of twelve drawn up in the 18th century by French astronomer Nicolas Louis de Lacaille and one of several depicting scientific instruments. Its name refers to a right angle in Latin, and is variously considered to represent a rule, a carpenter's square, a set square or a level. It remains one of the 88 modern constellations. Four of Norma's brighter stars make up a square in the field of faint stars. Gamma2 Normae is the brightest star with an apparent magnitude of 4.0. Mu Normae is one of the most luminous stars known, but is partially obscured by distance and cosmic dust. Four star systems are known to harbour planets.\" [2] \"Solomon Wariso (born 11 November 1966 in Portsmouth) is a retired English sprinter who competed primarily in the 200 and 400 metres.[1] He represented his country at two outdoor and three indoor World Championships and is the British record holder in the indoor 4 × 400 metres relay.\""},{"path":"https://docs.ropensci.org/googleLanguageR/articles/setup.html","id":"google-natural-language-api","dir":"Articles","previous_headings":"","what":"Google Natural Language API","title":"Introduction to googleLanguageR","text":"Google Natural Language API reveals structure meaning text offering powerful machine learning models easy use REST API. can use extract information people, places, events much , mentioned text documents, news articles blog posts. can also use understand sentiment product social media parse intent customer conversations happening call center messaging app. Read Google Natural Language API","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/articles/setup.html","id":"google-cloud-translation-api","dir":"Articles","previous_headings":"","what":"Google Cloud Translation API","title":"Introduction to googleLanguageR","text":"Google Cloud Translation API provides simple programmatic interface translating arbitrary string supported language. Translation API highly responsive, websites applications can integrate Translation API fast, dynamic translation source text source language target language (e.g. French English). Read Google Cloud Translation Website","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/articles/setup.html","id":"google-cloud-speech-api","dir":"Articles","previous_headings":"","what":"Google Cloud Speech API","title":"Introduction to googleLanguageR","text":"Google Cloud Speech API enables convert audio text applying neural network models easy use API. API recognizes 80 languages variants, support global user base. can transcribe text users dictating application’s microphone enable command--control voice among many use cases. Read Google Cloud Speech Website","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/articles/setup.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Introduction to googleLanguageR","text":"Create Google API Console Project Within project, add payment method project Within project, check relevant APIs activated Google Natural Language API Google Cloud Translation API Google Cloud Speech API Generate service account credential JSON file Return R, install library via devtools::install_github(\"MarkEdmondson1234/googleLanguageR\")","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/articles/setup.html","id":"authentication","dir":"Articles","previous_headings":"Usage","what":"Authentication","title":"Introduction to googleLanguageR","text":"best way authenticate use environment file. See ?Startup. usually place home directory. (e.g. using RStudio, click Home file explorer, create new TEXT file call .Renviron) Set file location download Google Project JSON file GL_AUTH argument: , load library auto-authenticate: can also authenticate directly using gl_auth function pointing JSON auth file: can call APIs via functions: gl_nlp() - Natural Langage API gl_speech() - Cloud Speech API gl_translate() - Cloud Translation API","code":"#.Renviron GL_AUTH=location_of_json_file.json library(googleLanguageR) # Setting scopes to https://www.googleapis.com/auth/cloud-platform # Set any additional scopes via options(googleAuthR.scopes.selected = c('scope1', 'scope2')) before loading library. # Successfully authenticated via location_of_json_file.json library(googleLanguageR) gl_auth(\"location_of_json_file.json\")"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/speech.html","id":"returned-structure","dir":"Articles","previous_headings":"","what":"Returned structure","title":"Google Cloud Speech-to-Text API","text":"API returns list two data.frame tibbles - transcript timings. Access via returned object $transcript $timings","code":"return <- gl_speech(test_audio, languageCode = \"en-GB\")  return$transcript # A tibble: 1 x 2 #                                                                                                         transcript confidence #                                                                                                              <chr>      <chr> #1 to administer medicine to animals is frequently a very difficult matter and yet sometimes it's necessary to do so  0.9711006  return$timings #   startTime endTime       word #1         0s  0.100s         to #2     0.100s  0.700s administer #3     0.700s  0.700s   medicine #4     0.700s  1.200s         to # etc..."},{"path":"https://docs.ropensci.org/googleLanguageR/articles/speech.html","id":"demo-for-google-cloud-speech-to-text-api","dir":"Articles","previous_headings":"","what":"Demo for Google Cloud Speech-to-Text API","title":"Google Cloud Speech-to-Text API","text":"test audio file installed package reads: “administer medicine animals frequently difficult matter, yet sometimes ’s necessary ” file sourced University Southampton’s speech detection (http://www-mobile.ecs.soton.ac.uk/) group fairly difficult computers parse, see :","code":"library(googleLanguageR) ## get the sample source file test_audio <- system.file(\"woman1_wb.wav\", package = \"googleLanguageR\")  ## its not perfect but...:) gl_speech(test_audio)$transcript  ## get alternative transcriptions gl_speech(test_audio, maxAlternatives = 2L)$transcript  gl_speech(test_audio, languageCode = \"en-GB\")$transcript  ## help it out with context for \"frequently\" gl_speech(test_audio,              languageCode = \"en-GB\",              speechContexts = list(phrases = list(\"is frequently a very difficult\")))$transcript"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/speech.html","id":"word-transcripts","dir":"Articles","previous_headings":"","what":"Word transcripts","title":"Google Cloud Speech-to-Text API","text":"API supports timestamps words recognised. outputted second data.frame holds three entries: startTime, endTime word.","code":"str(result$timings) #'data.frame':  152 obs. of  3 variables: # $ startTime: chr  \"0s\" \"0.100s\" \"0.500s\" \"0.700s\" ... # $ endTime  : chr  \"0.100s\" \"0.500s\" \"0.700s\" \"0.900s\" ... # $ word     : chr  \"a\" \"Dream\" \"Within\" \"A\" ...  result$timings #     startTime endTime       word #1          0s  0.100s          a #2      0.100s  0.500s      Dream #3      0.500s  0.700s     Within #4      0.700s  0.900s          A #5      0.900s      1s      Dream"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/speech.html","id":"custom-configurations","dir":"Articles","previous_headings":"","what":"Custom configurations","title":"Google Cloud Speech-to-Text API","text":"can also send arguments can help shape output, speaker diagrization (labelling different speakers) - use custom configurations create RecognitionConfig object. can done via R lists converted JSON via library(jsonlite) example shown :","code":"## Use a custom configuration my_config <- list(encoding = \"LINEAR16\",                   diarizationConfig = list(                     enableSpeakerDiarization = TRUE,                     minSpeakerCount = 2,                     maxSpeakCount = 3                   ))  # languageCode is required, so will be added if not in your custom config gl_speech(my_audio, languageCode = \"en-US\", customConfig = my_config)"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/speech.html","id":"asynchronous-calls","dir":"Articles","previous_headings":"","what":"Asynchronous calls","title":"Google Cloud Speech-to-Text API","text":"speech files greater 60 seconds don’t want results straight away, set asynch = TRUE call API. return object class \"gl_speech_op\" used within gl_speech_op() function check status task. task finished, return object form non-asynchronous case.","code":"async <- gl_speech(test_audio, asynch = TRUE) async ## Send to gl_speech_op() for status ## 4625920921526393240  result <- gl_speech_op(async)"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/text-to-speech.html","id":"returned-structure","dir":"Articles","previous_headings":"","what":"Returned structure","title":"Google Cloud Text-to-Speech API","text":"API returns audio file saved location specified output - default output.wav - don’t rename file overwritten next API call. advised set appropriate file extension change audio encoding (e.g. one .wav, .mp3 .ogg) audio payers recognise file format.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/articles/text-to-speech.html","id":"talk-languages","dir":"Articles","previous_headings":"","what":"Talk Languages","title":"Google Cloud Text-to-Speech API","text":"API can talk several different languages, added time. can get current list via function gl_talk_languages() online looking specific language, specify function call e.g. see Spanish (es) voices issue: can specify voice calling API via name argument, overrides gender languageCode argument: Otherwise, specify gender languageCode voice picked : languages yet supported, Danish. API return error cases.","code":"gl_talk_languages() # A tibble: 32 x 4    languageCodes name             ssmlGender naturalSampleRateHertz    <chr>         <chr>            <chr>                       <int>  1 es-ES         es-ES-Standard-A FEMALE                      24000  2 ja-JP         ja-JP-Standard-A FEMALE                      22050  3 pt-BR         pt-BR-Standard-A FEMALE                      24000  4 tr-TR         tr-TR-Standard-A FEMALE                      22050  5 sv-SE         sv-SE-Standard-A FEMALE                      22050  6 nl-NL         nl-NL-Standard-A FEMALE                      24000  7 en-US         en-US-Wavenet-A  MALE                        24000  8 en-US         en-US-Wavenet-B  MALE                        24000  9 en-US         en-US-Wavenet-C  FEMALE                      24000 10 en-US         en-US-Wavenet-D  MALE                        24000 gl_talk_languages(languageCode = \"es\") # A tibble: 1 x 4   languageCodes name             ssmlGender naturalSampleRateHertz   <chr>         <chr>            <chr>                       <int> 1 es-ES         es-ES-Standard-A FEMALE                      24000 gl_talk(\"Hasta la vista\", name = \"es-ES-Standard-A\") gl_talk(\"Would you like a cup of tea?\", gender = \"FEMALE\", languageCode = \"en-GB\")"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/text-to-speech.html","id":"support-for-ssml","dir":"Articles","previous_headings":"","what":"Support for SSML","title":"Google Cloud Text-to-Speech API","text":"Support also included Speech Synthesis Markup Language (SSML) - details using insert pauses, sounds breaks audio can found : https://cloud.google.com/text--speech/docs/ssml use, send SSML markup around text want talk set inputType= \"ssml\":","code":"# using SSML gl_talk('<speak>The <say-as interpret-as=\\\"characters\\\">SSML<\/say-as>   standard <break time=\\\"1s\\\"/>is defined by the   <sub alias=\\\"World Wide Web Consortium\\\">W3C<\/sub>.<\/speak>',   inputType =  \"ssml\")"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/text-to-speech.html","id":"effect-profiles","dir":"Articles","previous_headings":"","what":"Effect Profiles","title":"Google Cloud Text-to-Speech API","text":"can output audio files optimised playing various devices. use audio profiles, supply character vector available audio profiles listed : https://cloud.google.com/text--speech/docs/audio-profiles - audio profiles applied order given. instance effectsProfileIds=\"wearable-class-device\" optimise output smart watches, effectsProfileIds=c(\"wearable-class-device\",\"telephony-class-application\") apply sound filters optimised smart watches, telephonic devices.","code":"# using effects profiles gl_talk(\"This sounds great on headphones\",         effectsProfileIds = \"headphone-class-device\")"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/text-to-speech.html","id":"browser-speech-player","dir":"Articles","previous_headings":"","what":"Browser Speech player","title":"Google Cloud Text-to-Speech API","text":"Creating clicking audio file play can bit drag, also function play audio file , launching via browser. can piped via tidyverse’s %>% gl_talk_player() creates HTML file called player.html working directory default.","code":"library(magrittr) gl_talk(\"This is my audio player\") %>% gl_talk_player()  ## non-piped equivalent gl_talk_player(gl_talk(\"This is my audio player\"))"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/text-to-speech.html","id":"using-with-shiny","dir":"Articles","previous_headings":"Browser Speech player","what":"Using with Shiny","title":"Google Cloud Text-to-Speech API","text":"can Shiny , demonstrated example Shiny app included package. Click link video tutorial integrate text--speech Shiny app - demo uses text--speech talk user’s Google Analytics statistics. shiny module created help integrate text--speech Shiny apps, demo video :","code":"library(shiny) library(googleLanguageR)  # assume auto auth setup  ui <- fluidPage(   gl_talk_shinyUI(\"talk\") )  server <- function(input, output, session){       transcript <- reactive({         paste(\"This is a demo talking Shiny app!\")      })       callModule(gl_talk_shiny, \"talk\", transcript = transcript) }   shinyApp(ui = ui, server = server)"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/translation.html","id":"language-translation","dir":"Articles","previous_headings":"","what":"Language Translation","title":"Google Cloud Translation API","text":"Translate text via gl_translate. Note lot refined free version Google’s translation website. can choose target language via argument target. function automatically detect language define argument source. function also detect langauge. costs gl_translate_detect, usually cheaper detect translate one step. can pass vector text first attempted translate one API call - fails due greater API limits, attempt vectorising API calls. result calls slower, cost charged per character translated, per API call.","code":"library(googleLanguageR)  text <- \"to administer medicince to animals is frequently a very difficult matter, and yet sometimes it's necessary to do so\" ## translate British into Danish gl_translate(text, target = \"da\")$translatedText"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/translation.html","id":"html-support","dir":"Articles","previous_headings":"Language Translation","what":"HTML support","title":"Google Cloud Translation API","text":"can also supply web HTML select format='html' handle HTML tags give cleaner translation. Consider removing anything needed translated first, JavaScript CSS scripts using tools rvest - example shown :","code":"# translate webpages library(rvest) library(googleLanguageR)  my_url <- \"http://www.dr.dk/nyheder/indland/greenpeace-facebook-og-google-boer-foelge-apples-groenne-planer\"  ## in this case the content to translate is in css select .wcms-article-content read_html(my_url) %>% # read html   html_node(css = \".wcms-article-content\") %>%   # select article content   html_text %>% # extract text   gl_translate(format = \"html\") %>% # translate with html flag   dplyr::select(translatedText) # show translatedText column of output tibble"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/translation.html","id":"language-detection","dir":"Articles","previous_headings":"","what":"Language Detection","title":"Google Cloud Translation API","text":"function detects language: text , better. helps Danish… may better use cld2 translate offline first, avoid charges translation unnecessary (e.g. already English). verify online uncertain cases.","code":"## which language is this? gl_translate_detect(\"katten sidder på måtten\") cld2::detect_language(\"katten sidder på måtten\")"},{"path":"https://docs.ropensci.org/googleLanguageR/articles/translation.html","id":"translation-api-limits","dir":"Articles","previous_headings":"","what":"Translation API limits","title":"Google Cloud Translation API","text":"API limits three ways: characters per day, characters per 100 seconds, API requests per 100 seconds. can set API manager Google Cloud console: https://console.developers.google.com/apis/api/translate.googleapis.com/quotas library limit API calls characters API requests per 100 seconds. API automatically retry making requests quickly, also pause make sure send 100000 characters per 100 seconds.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Aleksander Dietrichson. Contributor. Mark Edmondson. Author, maintainer. John Muschelli. Contributor. Neal Richardson. Reviewer.            Neal reviewed package ropensci,                 see <https://github.com/ropensci/onboarding/issues/127> Julia Gustavsen. Reviewer.            Julia reviewed package ropensci,                 see <https://github.com/ropensci/onboarding/issues/127>","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Edmondson M (2024). googleLanguageR: Call Google's 'Natural Language' API, 'Cloud Translation' API, 'Cloud Speech' API 'Cloud Text--Speech' API. R package version 0.3.0.9000, https://github.com/ropensci/googleLanguageR, https://docs.ropensci.org/googleLanguageR/, http://code.markedmondson./googleLanguageR/.","code":"@Manual{,   title = {googleLanguageR: Call Google's 'Natural Language' API, 'Cloud Translation' API, 'Cloud Speech' API and 'Cloud Text-to-Speech' API},   author = {Mark Edmondson},   year = {2024},   note = {R package version 0.3.0.9000, https://github.com/ropensci/googleLanguageR, https://docs.ropensci.org/googleLanguageR/},   url = {http://code.markedmondson.me/googleLanguageR/}, }"},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"language-tools-for-r-via-google-machine-learning-apis","dir":"","previous_headings":"","what":"Language tools for R via Google Machine Learning APIs","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Read introduction blogpost rOpenSci’s blog package contains functions analysing language Google Cloud Machine Learning APIs Note paid services, need provide credit card details Google Project use . package can used user looking take advantage Google’s massive dataset train machine learning models. applications include: Translation speech another language text, via speech--text translation results spoen back Talking Shiny apps Identification sentiment within text, Twitter feeds Pulling objects sentence, help classify texts get metadata links Wikipedia . applications API results relevant business researchers looking scale text analysis.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"google-natural-language-api","dir":"","previous_headings":"","what":"Google Natural Language API","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Google Natural Language API reveals structure meaning text offering powerful machine learning models easy use REST API. can use extract information people, places, events much , mentioned text documents, news articles blog posts. can also use understand sentiment product social media parse intent customer conversations happening call center messaging app. Read Google Natural Language API","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"google-cloud-translation-api","dir":"","previous_headings":"","what":"Google Cloud Translation API","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Google Cloud Translation API provides simple programmatic interface translating arbitrary string supported language. Translation API highly responsive, websites applications can integrate Translation API fast, dynamic translation source text source language target language (e.g. French English). Read Google Cloud Translation Website","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"google-cloud-speech-to-text-api","dir":"","previous_headings":"","what":"Google Cloud Speech-to-Text API","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Google Cloud Speech--Text API enables convert audio text applying neural network models easy use API. API recognizes 80 languages variants, support global user base. can transcribe text users dictating application’s microphone enable command--control voice among many use cases. Read Google Cloud Speech Website","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"google-cloud-text-to-speech-api","dir":"","previous_headings":"","what":"Google Cloud Text-to-Speech API","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Google Cloud Text--Speech enables developers synthesize natural-sounding speech 30 voices, available multiple languages variants. applies DeepMind’s groundbreaking research WaveNet Google’s powerful neural networks deliver highest fidelity possible. easy--use API, can create lifelike interactions users, across many applications devices. Read Google Cloud Text--Speech Website","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Create Google API Console Project Within project, add payment method project Within project, check relevant APIs activated Google Natural Language API Google Cloud Translation API Google Cloud Speech--Text API Google Cloud Text--Speech API Generate service account credential JSON file first creating service account creating credentials service account Return R, install official release via install.packages(\"googleLanguageR\"), development version remotes::install_github(\"ropensci/googleLanguageR\")","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"docker-image","dir":"","previous_headings":"Installation","what":"Docker image","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Docker images publicly available. general gcr.io/gcer-public/googleLanguageR:$BRANCH_NAME carries GitHub branch’s version. gcr.io/gcer-public/googleLanguageR:CRAN - latest CRAN version gcr.io/gcer-public/googleLanguageR:master - latest GitHub master version gcr.io/gcer-public/googleLanguageR:feature - feature branch GitHub","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"authentication","dir":"","previous_headings":"Usage","what":"Authentication","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"best way authenticate use environment file. See ?Startup. usually place home directory. (e.g. using RStudio, click Home file explorer, create new TEXT file call .Renviron) Set file location download Google Project JSON file GL_AUTH argument: , load library auto-authenticate: can also authenticate directly using gl_auth function pointing JSON auth file: can call APIs via functions: gl_nlp() - Natural Langage API gl_speech() - Cloud Speech--Text API gl_translate() - Cloud Translation API gl_talk() - Cloud Text--Speech API","code":"#.Renviron GL_AUTH=location_of_json_file.json library(googleLanguageR) library(googleLanguageR) gl_auth(\"location_of_json_file.json\")"},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"natural-language-api","dir":"","previous_headings":"","what":"Natural Language API","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Natural Language API returns natural language understanding technolgies. can call individually, default return . available returns : Entity analysis - Finds named entities (currently proper names common nouns) text along entity types, salience, mentions entity, properties. possible, also return metadata entity Wikipedia URL. using v1beta2 endpoint also includes sentiment entity. Syntax - Analyzes syntax text provides sentence boundaries tokenization along part speech tags, dependency trees, properties. Sentiment - overall sentiment text, represented magnitude [0, +inf] score -1.0 (negative sentiment) 1.0 (positive sentiment).","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"demo-for-entity-analysis","dir":"","previous_headings":"Natural Language API","what":"Demo for Entity Analysis","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"can pass vector text call API element. return list responses, response list tibbles holding different types analysis. See examples details website via vignette(\"nlp\", package = \"googleLanguageR\")","code":"texts <- c(\"to administer medicince to animals is frequently a very difficult matter, and yet sometimes it's necessary to do so\",           \"I don't know how to make a text demo that is sensible\") nlp_result <- gl_nlp(texts)  # two results of lists of tibbles str(nlp_result, max.level = 2)"},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"google-translation-api","dir":"","previous_headings":"","what":"Google Translation API","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"can detect language via gl_translate_detect, translate detect language via gl_translate Note lot refined free version Google’s translation website. See examples details website via vignette(\"translate\", package = \"googleLanguageR\")","code":"text <- \"to administer medicine to animals is frequently a very difficult matter, and yet sometimes it's necessary to do so\" ## translate British into Danish gl_translate(text, target = \"da\")$translatedText"},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"google-cloud-speech-to-text-api-1","dir":"","previous_headings":"","what":"Google Cloud Speech-to-Text API","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Cloud Speech--Text API provides audio transcription. accessible via gl_speech function. test audio file installed package reads: “administer medicine animals frequently difficult matter, yet sometimes ’s necessary ” file sourced University Southampton’s speech detection (http://www-mobile.ecs.soton.ac.uk/newcomms/) group fairly difficult computers parse, see : See examples details website via vignette(\"speech\", package = \"googleLanguageR\")","code":"## get the sample source file test_audio <- system.file(\"woman1_wb.wav\", package = \"googleLanguageR\")  ## its not perfect but...:) gl_speech(test_audio)$transcript       ## # A tibble: 1 x 2     ##   transcript                                                    confidence     ##   <chr>                                                         <chr>          ## 1 to administer medicine to animals is frequency of very diffi… 0.9180294"},{"path":"https://docs.ropensci.org/googleLanguageR/index.html","id":"google-cloud-text-to-speech-api-1","dir":"","previous_headings":"","what":"Google Cloud Text-to-Speech API","title":"Call Googles Natural Language API, Cloud Translation API, \n  Cloud Speech API and Cloud Text-to-Speech' API","text":"Cloud Text--Speech API turns text talk audio files. accessible via gl_talk function. use, supply text function: See examples details website via vignette(\"text--speech\", package = \"googleLanguageR\")","code":"gl_talk(\"This is a talking computer.  Hello Dave.\")"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_auth.html","id":null,"dir":"Reference","previous_headings":"","what":"Authenticate with Google language API services — gl_auth","title":"Authenticate with Google language API services — gl_auth","text":"Authenticate Google language API services","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_auth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Authenticate with Google language API services — gl_auth","text":"","code":"gl_auth(json_file)  gl_auto_auth(...)"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_auth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Authenticate with Google language API services — gl_auth","text":"json_file Authentication json file downloaded Google Project ... additional argument pass gar_attach_auto_auth.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_auth.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Authenticate with Google language API services — gl_auth","text":"best way authenticate use environment argument pointing authentication file. Set file location download Google Project JSON file GL_AUTH argument , load library auto-authenticate However, can authenticate directly using function pointing JSON auth file.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_auth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Authenticate with Google language API services — gl_auth","text":"","code":"if (FALSE) { library(googleLanguageR) gl_auth(\"location_of_json_file.json\") }  if (FALSE) { library(googleLanguageR) gl_auto_auth() gl_auto_auth(environment_var = \"GAR_AUTH_FILE\") }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_nlp.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Natural Language Analysis — gl_nlp","title":"Perform Natural Language Analysis — gl_nlp","text":"Analyse text entities, sentiment, syntax categorisation using Google Natural Language API","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_nlp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Natural Language Analysis — gl_nlp","text":"","code":"gl_nlp(   string,   nlp_type = c(\"annotateText\", \"analyzeEntities\", \"analyzeSentiment\", \"analyzeSyntax\",     \"analyzeEntitySentiment\", \"classifyText\"),   type = c(\"PLAIN_TEXT\", \"HTML\"),   language = c(\"en\", \"zh\", \"zh-Hant\", \"fr\", \"de\", \"it\", \"ja\", \"ko\", \"pt\", \"es\"),   encodingType = c(\"UTF8\", \"UTF16\", \"UTF32\", \"NONE\") )"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_nlp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Natural Language Analysis — gl_nlp","text":"string vector text detect language , Google Cloud Storage URI(s) nlp_type type Natural Language Analysis perform.  default annotateText perform features one call. type Whether input text plain text HTML page language Language source, must supported API. encodingType Text encoding caller uses process output","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_nlp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Natural Language Analysis — gl_nlp","text":"list following objects, fields asked via nlp_type: sentences - Sentences input document tokens - Tokens, along syntactic information, input document entities - Entities, along semantic information, input document documentSentiment - overall sentiment document classifyText -Classification document language - language text, language specified request , specified, automatically-detected language text - original text passed API. NA passed due zero-length etc.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_nlp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform Natural Language Analysis — gl_nlp","text":"string can character vector, location file content Google cloud Storage.   URI must form gs://bucket_name/object_name Encoding type can usually left default UTF8.   Read current language support available ","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_nlp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Natural Language Analysis — gl_nlp","text":"","code":"if (FALSE) {  text <- \"to administer medicince to animals is frequently a very difficult matter,   and yet sometimes it's necessary to do so\" nlp <- gl_nlp(text)  nlp$sentences  nlp$tokens  nlp$entities  nlp$documentSentiment  ## vectorised input texts <- c(\"The cat sat one the mat\", \"oh no it didn't you fool\") nlp_results <- gl_nlp(texts)    }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech.html","id":null,"dir":"Reference","previous_headings":"","what":"Call Google Speech API — gl_speech","title":"Call Google Speech API — gl_speech","text":"Turn audio text","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call Google Speech API — gl_speech","text":"","code":"gl_speech(   audio_source,   encoding = c(\"LINEAR16\", \"FLAC\", \"MULAW\", \"AMR\", \"AMR_WB\", \"OGG_OPUS\",     \"SPEEX_WITH_HEADER_BYTE\"),   sampleRateHertz = NULL,   languageCode = \"en-US\",   maxAlternatives = 1L,   profanityFilter = FALSE,   speechContexts = NULL,   asynch = FALSE,   customConfig = NULL )"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call Google Speech API — gl_speech","text":"audio_source File location audio data, Google Cloud Storage URI encoding Encoding audio data sent sampleRateHertz Sample rate Hertz audio data. Valid values 8000-48000. Optimal default left NULL 16000 languageCode Language supplied audio BCP-47 language tag maxAlternatives Maximum number recognition hypotheses returned. 0-30 profanityFilter TRUE attempt filter profanities speechContexts optional character vector context assist speech recognition asynch audio_source greater 60 seconds, set TRUE return asynchronous call customConfig [optional] RecognitionConfig object converted list JSON via toJSON - see RecognitionConfig documentation. languageCode taken functions arguments present since required.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call Google Speech API — gl_speech","text":"list two tibbles:  $transcript, tibble transcript confidence; $timings, tibble contains startTime, endTime per word.  maxAlternatives greater 1, transcript return near-duplicate rows interpretations text.  asynch TRUE, operation need pass gl_speech_op get finished result.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Call Google Speech API — gl_speech","text":"Google Cloud Speech API enables developers convert audio text applying powerful neural network models easy use API. API recognizes 80 languages variants, support global user base. can transcribe text users dictating application’s microphone, enable command--control voice, transcribe audio files, among many use cases. Recognize audio uploaded request, integrate audio storage Google Cloud Storage, using technology Google uses power products.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech.html","id":"audioencoding","dir":"Reference","previous_headings":"","what":"AudioEncoding","title":"Call Google Speech API — gl_speech","text":"Audio encoding data sent audio message. encodings support 1 channel (mono) audio. FLAC WAV include header describes bytes audio follow header. encodings raw audio bytes header. best results, audio source captured transmitted using lossless encoding (FLAC LINEAR16). Recognition accuracy may reduced lossy codecs, include codecs listed section, used capture transmit audio, particularly background noise present. Read audio encodings https://cloud.google.com/speech/docs/encoding","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech.html","id":"wordinfo","dir":"Reference","previous_headings":"","what":"WordInfo","title":"Call Google Speech API — gl_speech","text":"startTime - Time offset relative beginning audio, corresponding start spoken word. endTime - Time offset relative beginning audio, corresponding end spoken word. word - word corresponding set information.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call Google Speech API — gl_speech","text":"","code":"if (FALSE) {  test_audio <- system.file(\"woman1_wb.wav\", package = \"googleLanguageR\") result <- gl_speech(test_audio)  result$transcript result$timings  result2 <- gl_speech(test_audio, maxAlternatives = 2L) result2$transcript  result_brit <- gl_speech(test_audio, languageCode = \"en-GB\")   ## make an asynchronous API request (mandatory for sound files over 60 seconds) asynch <- gl_speech(test_audio, asynch = TRUE)  ## Send to gl_speech_op() for status or finished result gl_speech_op(asynch)  ## Upload to GCS bucket for long files > 60 seconds test_gcs <- \"gs://mark-edmondson-public-files/googleLanguageR/a-dream-mono.wav\" gcs <- gl_speech(test_gcs, sampleRateHertz = 44100L, asynch = TRUE) gl_speech_op(gcs)  ## Use a custom configuration my_config <- list(encoding = \"LINEAR16\",                   diarizationConfig = list(                     enableSpeakerDiarization = TRUE,                     minSpeakerCount = 2,                     maxSpeakCount = 3                     ))  # languageCode is required, so will be added if not in your custom config gl_speech(my_audio, languageCode = \"en-US\", customConfig = my_config)  }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech_op.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a speech operation — gl_speech_op","title":"Get a speech operation — gl_speech_op","text":"asynchronous calls audio 60 seconds, returns finished job","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech_op.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a speech operation — gl_speech_op","text":"","code":"gl_speech_op(operation = .Last.value)"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech_op.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a speech operation — gl_speech_op","text":"operation speech operation object gl_speech asynch = TRUE","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech_op.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a speech operation — gl_speech_op","text":"operation still running, another operation object.  done, result per gl_speech","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_speech_op.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a speech operation — gl_speech_op","text":"","code":"if (FALSE) {  test_audio <- system.file(\"woman1_wb.wav\", package = \"googleLanguageR\")  ## make an asynchronous API request (mandatory for sound files over 60 seconds) asynch <- gl_speech(test_audio, asynch = TRUE)  ## Send to gl_speech_op() for status or finished result gl_speech_op(asynch)  }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform text to speech — gl_talk","title":"Perform text to speech — gl_talk","text":"Synthesizes speech synchronously: receive results text input processed.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform text to speech — gl_talk","text":"","code":"gl_talk(   input,   output = \"output.wav\",   languageCode = \"en\",   gender = c(\"SSML_VOICE_GENDER_UNSPECIFIED\", \"MALE\", \"FEMALE\", \"NEUTRAL\"),   name = NULL,   audioEncoding = c(\"LINEAR16\", \"MP3\", \"OGG_OPUS\"),   speakingRate = 1,   pitch = 0,   volumeGainDb = 0,   sampleRateHertz = NULL,   inputType = c(\"text\", \"ssml\"),   effectsProfileIds = NULL )"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform text to speech — gl_talk","text":"input text turn speech output save speech audio file languageCode language voice BCP-47 language code gender gender voice, available name Name voice, see list via gl_talk_languages supported voices.  Set NULL make service choose voice based languageCode gender. audioEncoding Format requested audio stream speakingRate Speaking rate/speed 0.25 4.0 pitch Speaking pitch -20.0 20.0 semitones. volumeGainDb Volumne gain dB sampleRateHertz Sample rate returned audio inputType Choose text (default) SSML markup. input text must SSML markup choose ssml effectsProfileIds Optional. identifier selects 'audio effects' profiles applied (post synthesized) text speech. Effects applied top order given","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform text to speech — gl_talk","text":"file output name supplied output","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform text to speech — gl_talk","text":"Requires Cloud Text--Speech API activated Google Cloud project. Supported voices https://cloud.google.com/text--speech/docs/voices can imported R via gl_talk_languages play audio code via browser see gl_talk_player use Speech Synthesis Markup Language (SSML) select inputType=ssml - details using insert pauses, sounds breaks audio can found : https://cloud.google.com/text--speech/docs/ssml use audio profiles, supply character vector available audio profiles listed : https://cloud.google.com/text--speech/docs/audio-profiles - audio profiles applied order given.  instance effectsProfileIds=\"wearable-class-device\" optimise output smart watches, effectsProfileIds=c(\"wearable-class-device\",\"telephony-class-application\") apply sound filters optimised smart watches, telephonic devices.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform text to speech — gl_talk","text":"","code":"if (FALSE) { library(magrittr) gl_talk(\"The rain in spain falls mainly in the plain\",         output = \"output.wav\")  gl_talk(\"Testing my new audio player\") %>% gl_talk_player()  # using SSML gl_talk('<speak>The <say-as interpret-as=\\\"characters\\\">SSML<\/say-as>   standard <break time=\\\"1s\\\"/>is defined by the   <sub alias=\\\"World Wide Web Consortium\\\">W3C<\/sub>.<\/speak>',   inputType =  \"ssml\")  # using effects profiles gl_talk(\"This sounds great on headphones\",         effectsProfileIds = \"headphone-class-device\")  }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_languages.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a list of voices available for text to speech — gl_talk_languages","title":"Get a list of voices available for text to speech — gl_talk_languages","text":"Returns list voices supported synthesis.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_languages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a list of voices available for text to speech — gl_talk_languages","text":"","code":"gl_talk_languages(languageCode = NULL)"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_languages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a list of voices available for text to speech — gl_talk_languages","text":"languageCode BCP-47 language tag.  specified, return voices can used synthesize languageCode","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_player.html","id":null,"dir":"Reference","previous_headings":"","what":"Play audio in a browser — gl_talk_player","title":"Play audio in a browser — gl_talk_player","text":"uses HTML5 audio tags play audio browser","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_player.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Play audio in a browser — gl_talk_player","text":"","code":"gl_talk_player(audio = \"output.wav\", html = \"player.html\")"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_player.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Play audio in a browser — gl_talk_player","text":"audio file location audio file.  Must supported HTML5 html html file location created host audio","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_player.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Play audio in a browser — gl_talk_player","text":"platform neutral way play audio easy, uses browser play instead.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_player.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Play audio in a browser — gl_talk_player","text":"","code":"if (FALSE) {  gl_talk(\"Testing my new audio player\") %>% gl_talk_player()  }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Speak in Shiny module (server) — gl_talk_shiny","title":"Speak in Shiny module (server) — gl_talk_shiny","text":"Call via shiny::callModule(gl_talk_shiny, \"your_id\")","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Speak in Shiny module (server) — gl_talk_shiny","text":"","code":"gl_talk_shiny(   input,   output,   session,   transcript,   ...,   autoplay = TRUE,   controls = TRUE,   loop = FALSE,   keep_wav = FALSE )"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Speak in Shiny module (server) — gl_talk_shiny","text":"input shiny input output shiny output session shiny session transcript (reactive) text talk ... Arguments passed gl_talk languageCode language voice BCP-47 language code name Name voice, see list via gl_talk_languages supported voices.  Set NULL make service choose voice based languageCode gender. gender gender voice, available audioEncoding Format requested audio stream speakingRate Speaking rate/speed 0.25 4.0 pitch Speaking pitch -20.0 20.0 semitones. volumeGainDb Volumne gain dB sampleRateHertz Sample rate returned audio inputType Choose text (default) SSML markup. input text must SSML markup choose ssml effectsProfileIds Optional. identifier selects 'audio effects' profiles applied (post synthesized) text speech. Effects applied top order given autoplay passed HTML audio player - default TRUE plays load controls passed HTML audio player - default TRUE shows controls loop passed HTML audio player - default FALSE loop keep_wav keep generated wav files TRUE.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_shinyUI.html","id":null,"dir":"Reference","previous_headings":"","what":"Speak in Shiny module (ui) — gl_talk_shinyUI","title":"Speak in Shiny module (ui) — gl_talk_shinyUI","text":"Speak Shiny module (ui)","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_shinyUI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Speak in Shiny module (ui) — gl_talk_shinyUI","text":"","code":"gl_talk_shinyUI(id)"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_shinyUI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Speak in Shiny module (ui) — gl_talk_shinyUI","text":"id Shiny id","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_talk_shinyUI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Speak in Shiny module (ui) — gl_talk_shinyUI","text":"Shiny Module use gl_talk_shiny.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate.html","id":null,"dir":"Reference","previous_headings":"","what":"Translate the language of text within a request — gl_translate","title":"Translate the language of text within a request — gl_translate","text":"Translate character vectors via Google Translate API","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Translate the language of text within a request — gl_translate","text":"","code":"gl_translate(   t_string,   target = \"en\",   format = c(\"text\", \"html\"),   source = \"\",   model = c(\"nmt\", \"base\") )"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Translate the language of text within a request — gl_translate","text":"t_string character vector text detect language target target language format Whether text plain HTML source Specify language translate . detect left default model translation model use","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Translate the language of text within a request — gl_translate","text":"tibble translatedText detectedSourceLanguage text length equal vector text passed .","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Translate the language of text within a request — gl_translate","text":"can translate vector strings, although many one call   broken one API call per element.   cost charging per character translated, take longer. translating HTML set format = \"html\". Consider removing anything needed translated first,   JavaScript CSS scripts. See example rvest API limits three ways: characters per day, characters per 100 seconds,   API requests per 100 seconds. can set API manager   https://console.developers.google.com/apis/api/translate.googleapis.com/quotas","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Translate the language of text within a request — gl_translate","text":"","code":"if (FALSE) {  text <- \"to administer medicine to animals is frequently a very difficult matter,   and yet sometimes it's necessary to do so\"  gl_translate(text, target = \"ja\")  # translate webpages using rvest to process beforehand library(rvest) library(googleLanguageR)  # translate webpages  # dr.dk article my_url <- \"http://bit.ly/2yhrmrH\"  ## in this case the content to translate is in css selector '.wcms-article-content' read_html(my_url) %>%   html_node(css = \".wcms-article-content\") %>%   html_text %>%   gl_translate(format = \"html\")  }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_detect.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect the language of text within a request — gl_translate_detect","title":"Detect the language of text within a request — gl_translate_detect","text":"Detect language text within request","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_detect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect the language of text within a request — gl_translate_detect","text":"","code":"gl_translate_detect(string)"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_detect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect the language of text within a request — gl_translate_detect","text":"string character vector text detect language ","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_detect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect the language of text within a request — gl_translate_detect","text":"tibble detected languages columns confidence, isReliable, language, text length equal vector text passed .","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_detect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect the language of text within a request — gl_translate_detect","text":"Consider using library(cld2) cld2::detect_language instead offline, since free local without needing paid API call. gl_translate also returns detection language, also wish one step via function.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_detect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect the language of text within a request — gl_translate_detect","text":"","code":"if (FALSE) {  gl_translate_detect(\"katten sidder på måtten\") # Detecting language: 39 characters - katten sidder på måtten... # confidence isReliable language                    text # 1   0.536223      FALSE       da katten sidder på måtten   }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_document.html","id":null,"dir":"Reference","previous_headings":"","what":"Translate document — gl_translate_document","title":"Translate document — gl_translate_document","text":"Translate document via Google Translate API","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_document.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Translate document — gl_translate_document","text":"","code":"gl_translate_document(   d_path,   target = \"es-ES\",   output_path = \"out.pdf\",   format = c(\"pdf\"),   source = \"en-UK\",   model = c(\"nmt\", \"base\"),   location = \"global\" )"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_document.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Translate document — gl_translate_document","text":"d_path path document translated output_path save translated document format currently pdf-files supported","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_document.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Translate document — gl_translate_document","text":"output filename","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_document.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Translate document — gl_translate_document","text":"","code":"if (FALSE) { gl_translate_document(system.file(package = \"googleLanguageR\",\"test-doc.pdf\"), \"no\")  }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_languages.html","id":null,"dir":"Reference","previous_headings":"","what":"Lists languages from Google Translate API — gl_translate_languages","title":"Lists languages from Google Translate API — gl_translate_languages","text":"Returns list supported languages translation.","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_languages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lists languages from Google Translate API — gl_translate_languages","text":"","code":"gl_translate_languages(target = \"en\")"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_languages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lists languages from Google Translate API — gl_translate_languages","text":"target specified, language names localized target language","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_languages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lists languages from Google Translate API — gl_translate_languages","text":"tibble supported languages","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_languages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lists languages from Google Translate API — gl_translate_languages","text":"Supported language codes, generally consisting ISO 639-1 identifier. (E.g. 'en', 'ja'). certain cases, BCP-47 codes including language + region identifiers returned (e.g. 'zh-TW', 'zh-CH')","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/gl_translate_languages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lists languages from Google Translate API — gl_translate_languages","text":"","code":"if (FALSE) {  # default english names of languages supported gl_translate_languages()  # specify a language code to get other names, such as Danish gl_translate_languages(\"da\")  }"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/googleLanguageR.html","id":null,"dir":"Reference","previous_headings":"","what":"googleLanguageR — googleLanguageR","title":"googleLanguageR — googleLanguageR","text":"package contains functions analysing language   Google Cloud Machine Learning APIs","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/googleLanguageR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"googleLanguageR — googleLanguageR","text":"examples documentation see vignettes website: http://code.markedmondson./googleLanguageR/","code":""},{"path":[]},{"path":"https://docs.ropensci.org/googleLanguageR/reference/is.NullOb.html","id":null,"dir":"Reference","previous_headings":"","what":"A helper function that tests whether an object is either NULL _or_\na list of NULLs — is.NullOb","title":"A helper function that tests whether an object is either NULL _or_\na list of NULLs — is.NullOb","text":"helper function tests whether object either NULL _or_ list NULLs","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/is.NullOb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A helper function that tests whether an object is either NULL _or_\na list of NULLs — is.NullOb","text":"","code":"is.NullOb(x)"},{"path":"https://docs.ropensci.org/googleLanguageR/reference/rmNullObs.html","id":null,"dir":"Reference","previous_headings":"","what":"Recursively step down into list, removing all such objects — rmNullObs","title":"Recursively step down into list, removing all such objects — rmNullObs","text":"Recursively step list, removing objects","code":""},{"path":"https://docs.ropensci.org/googleLanguageR/reference/rmNullObs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recursively step down into list, removing all such objects — rmNullObs","text":"","code":"rmNullObs(x)"}]
